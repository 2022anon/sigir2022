We release the data and codes used in our paper.
# Data
We uploaded the core codes in File "data":  

File "yelp" contains the synthetic semi-structured training pairs and generated summaries.
We randomly sample 30 training pairs from the synthetic training dataset.
      summary_yelp_train: the summary of the samples (Output) 
      OAs_yelp_train: the noisy opinion-aspect pairs of the samples (Input)
      ISs_yelp_train: the noisy implicit sentences of the samples (Input)
      yelp_result: the summaries generated by TBA with BART, which is the best result on Yelp dataset.	  

File "amazon" contains the synthetic semi-structured training pairs and generated summaries.
We randomly sample 30 training pairs from the synthetic training dataset.
      summary_amazon_train: the summary of the samples (Output) 
      OAs_amazon_train: the noisy opinion-aspect pairs of the samples (Input)
      ISs_amazon_train: the noisy implicit sentences of the samples (Input)
      amazon_result: the summaries generated by TBA with BART, which is the best result on Amazon dataset.

File "RT" contains the synthetic semi-structured training pairs and generated summaries.
We randomly sample 30 training pairs from the synthetic training dataset.
      summary_rt_train: the summary of the samples (Output) 
      OAs_rt_train: the noisy opinion-aspect pairs of the samples (Input)
      ISs_rt_train: the noisy implicit sentences of the samples (Input)
      rt_result: the summaries generated by TBA with BART, which is the best result on RottenTomatoes dataset.


# Codes
We uploaded the core codes in File "code":  
*File "basic" containes the codes of basic model.*   
*File "advance" containes the codes of advanced model.*  
Both basic and advanced models are implemented based on [Fairseq](https://github.com/pytorch/fairseq) framework provided.

